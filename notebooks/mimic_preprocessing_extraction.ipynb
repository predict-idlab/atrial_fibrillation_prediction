{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "plt.rcParams[\"axes.grid\"] = False #disable white lines which are present in google colab for matplotlib\n",
    "import numpy as np\n",
    "import datetime\n",
    "today = datetime.datetime.today() #To work with datetime values. Only relative time matters in this project, so selecting a random date is not a problem. \n",
    "from sklearn.metrics import classification_report,auc,r2_score,matthews_corrcoef\n",
    "import shap\n",
    "from catboost import CatBoostClassifier,CatBoostRegressor,Pool\n",
    "from catboost.utils import get_roc_curve\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from scipy.stats import linregress,ttest_ind,ranksums\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "path = \"../../../MIMIC_IV/mimic-iv-1.0/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV preparation for easy extraction of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_items = pd.read_csv(path+\"icu/csv/d_items.csv\",sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_items[df_d_items.label.str.contains(\"height\",regex=True,flags=re.IGNORECASE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_labitems = pd.read_csv(path+\"hosp/csv/d_labitems.csv\",sep=',')\n",
    "d_labitems.label = d_labitems.label.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_labitems[d_labitems.label.str.contains(\"oxygen\",regex=True,flags=re.IGNORECASE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHARTEVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 98 iterations with this code. This will take 2 hours\n",
    "for chunk in tqdm.tqdm(pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/icu/csv/chartevents.csv\",sep=',',\n",
    "                             chunksize=10000000, \n",
    "                             iterator=True,low_memory=False),ascii=True):\n",
    "        \n",
    "        for itemid in chunk.itemid.unique():\n",
    "            path = \"Data/MIMIC/mimic-iv-1.0/icu/csv/chartevents/\"+str(itemid)+\".csv\"\n",
    "            \n",
    "            if os.path.exists(path):\n",
    "                chunk[chunk.itemid==itemid].to_csv(path,mode='a',index=False, header=False)\n",
    "            else:\n",
    "                chunk[chunk.itemid==itemid].to_csv(path,index=False)\n",
    "            \n",
    "        chunk = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHART EVENTS Feature concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code loop will take around 7 minutes, saving another 5 minutes\n",
    "chart_items_af_features = None\n",
    "\n",
    "chart_items_itemids = [\n",
    "                    220074, #CVD\n",
    "                    223834, #O2 Flow\n",
    "                    220045, #Heart rate\n",
    "                    220339, #PEEP set\n",
    "                    224828, #Arterial Base Excess = B.E.\n",
    "                    220050, #Arterial Blood Pressure systolic\n",
    "                    224639, #Daily Weight\n",
    "                    226707, #Height\n",
    "                    226512, #Admission  Weight (Kg)\n",
    "                    223835, #Inspired O2 Fraction\n",
    "                    220210, #respiratory rate monitor\n",
    "                    220052\n",
    "                    ] #Arterial blood pressure mean\n",
    "                       \n",
    "\n",
    "for itemid in tqdm.tqdm(chart_items_itemids,ascii=True):\n",
    "    if os.path.exists(path+\"icu/csv/chartevents/\"+str(itemid)+\".csv\"):\n",
    "        if chart_items_af_features is None:\n",
    "            chart_items_af_features = pd.read_csv(path+\"icu/csv/chartevents/\"+str(itemid)+\".csv\")[[\"subject_id\",\"hadm_id\",\"stay_id\",\"storetime\",\"itemid\",\"value\",\"valuenum\",\"valueuom\"]]\n",
    "        else:\n",
    "            chart_items_af_features = pd.concat([chart_items_af_features,pd.read_csv(path+\"icu/csv/chartevents/\"+str(itemid)+\".csv\")[[\"subject_id\",\"hadm_id\",\"stay_id\",\"storetime\",\"itemid\",\"value\",\"valuenum\",\"valueuom\"]]])\n",
    "print(\"SAVING\")\n",
    "chart_items_af_features.to_csv(\"Data/MIMIC_extracted/chart_items_af_features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LABEVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 98 iterations with this code. This will take 2 hours\n",
    "for chunk in tqdm.tqdm(pd.read_csv(path+\"hosp/csv/labevents.csv\",sep=',',\n",
    "                             chunksize=10000000, \n",
    "                             iterator=True,low_memory=False),ascii=True):\n",
    "        \n",
    "        for itemid in chunk.itemid.unique():\n",
    "            path = path+\"hosp/csv/labevents/\"+str(itemid)+\".csv\"\n",
    "            \n",
    "            if os.path.exists(path):\n",
    "                chunk[chunk.itemid==itemid].to_csv(path,mode='a',index=False, header=False)\n",
    "            else:\n",
    "                chunk[chunk.itemid==itemid].to_csv(path,index=False)\n",
    "            \n",
    "        chunk = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB EVENTS Feature concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code loop will take around 7 minutes, saving another 5 minutes\n",
    "lab_items_af_features = None\n",
    "\n",
    "lab_items_itemids = [51265, #Platelet count\n",
    "                     50889, #C-reactive protein blood\n",
    "                     51275, #PTT (but is actually APTT) blood\n",
    "                     50821, #PO2 blood\n",
    "                     50818, #Pco2 monitor blood\n",
    "                     50820, #pH blood\n",
    "                     50882, #Bicarbonate (HCO3)\n",
    "                     50813, #Lactate blood\n",
    "                     51222, #Hemoglobin blood\n",
    "                     50817, #Oxygen Saturation\n",
    "                     50970, #phosphate blood\n",
    "                     51006] #urea nitrogen blood\n",
    "                       \n",
    "\n",
    "for itemid in tqdm.tqdm(lab_items_itemids,ascii=True):\n",
    "    if os.path.exists(path+\"hosp/csv/labevents/\"+str(itemid)+\".csv\"):\n",
    "        if lab_items_af_features is None:\n",
    "            lab_items_af_features = pd.read_csv(path+\"hosp/csv/labevents/\"+str(itemid)+\".csv\")[[\"subject_id\",\"hadm_id\",\"storetime\",\"itemid\",\"value\",\"valuenum\",\"valueuom\"]]\n",
    "        else:\n",
    "            lab_items_af_features = pd.concat([lab_items_af_features,pd.read_csv(path+\"hosp/csv/labevents/\"+str(itemid)+\".csv\")[[\"subject_id\",\"hadm_id\",\"storetime\",\"itemid\",\"value\",\"valuenum\",\"valueuom\"]]])\n",
    "print(\"SAVING\")\n",
    "lab_items_af_features.to_csv(\"Data/MIMIC_extracted/lab_items_af_features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputevents/inputevents Feature Concatenation\n",
    "Fluid-balance should be directly calculated from inputevents and outputevents while creating features as the dataset is ready for a simple window application method. Inputevents has mixed types and only the ml is selected. For outputevents this is all ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_af_features = None\n",
    "\n",
    "for chunk in tqdm.tqdm(pd.read_csv(path+\"icu/csv/outputevents.csv\",sep=',',\n",
    "                             chunksize=10000000, \n",
    "                             iterator=True,low_memory=False),ascii=True):\n",
    "        \n",
    "        if output_af_features is not None :\n",
    "            output_af_features = output_af_features.append(chunk[chunk.itemid==226559])\n",
    "        else:\n",
    "            output_af_features = chunk[chunk.itemid==226559]\n",
    "            \n",
    "output_af_features.to_csv(\"Data/MIMIC_extracted/output_af_features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ev = pd.read_csv(path+\"icu/csv/inputevents.csv\",sep=',',\n",
    "                             nrows=100000)\n",
    "inp_ev[(inp_ev.amountuom==\"ml\") | (inp_ev.amountuom==\"L\") | (inp_ev.amountuom==\"uL\")].to_csv(\"Data/MIMIC_extracted/input_fluid_af_features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ev = pd.read_csv(path+\"/icu/csv/outputevents.csv\",sep=',',\n",
    "                             nrows=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputevents concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emar_medications_r = r'Magnesium Sulfate|Calcium Carbonate|Calcium Acetate|Calcium Gluconate|bumetanide|furosemide|norepinephrine|propofol|fentanyl citrate|dopamine|fentanyl'\n",
    "df_d_items[(df_d_items.label.str.contains(emar_medications_r,flags=re.IGNORECASE, regex=True))][[\"itemid\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputevents_medication_features = [\n",
    "    221456,# \tCalcium Gluconate\n",
    "    221662,# \tDopamine\n",
    "    221794,# \tFurosemide (Lasix)\n",
    "    221906,# \tNorepinephrine\n",
    "    222011,# \tMagnesium Sulfate\n",
    "    222168,# \tPropofol\n",
    "    227210,# \tPropofol (Intubation)\n",
    "    227523,# \tMagnesium Sulfate (Bolus)\n",
    "    221744,#    Fentanyl\n",
    "    227524,# \tMagnesium Sulfate (OB-GYN)\n",
    "    227525,# \tCalcium Gluconate (CRRT)\n",
    "    228317,# \tCalcium Gluconate (Bolus)_OLD_1\n",
    "    228340,# \tFurosemide (Lasix) 250/50\n",
    "    229639,# \tBumetanide (Bumex)\n",
    "    229640# \tCalcium Gluconate (Bolus)\n",
    "    ]\n",
    "\n",
    "inputevents = pd.read_csv(path+\"icu/csv/inputevents.csv\")\n",
    "df_AF_medication = inputevents[inputevents.itemid.isin(inputevents_medication_features)][[\n",
    "                            'subject_id', 'hadm_id', 'stay_id', 'starttime', 'endtime', 'rateuom',\n",
    "                               'itemid', 'amount',  'rate',  'totalamount'\n",
    "                        ]]\n",
    "\n",
    "df_AF_medication.loc[(~df_AF_medication.rate.isna())&(df_AF_medication.rateuom.str.contains(\"hour\")),\"rate\"] = df_AF_medication[(~df_AF_medication.rate.isna())&(df_AF_medication.rateuom.str.contains(\"hour\"))].rate * 60\n",
    "\n",
    "df_AF_medication.to_csv(\"Data/MIMIC_extracted/df_AF_inputevents_medication.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputevents = pd.read_csv(path+\"icu/csv/inputevents.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medication EVENTS Feature concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emar_medications_r = r'Magnesium Sulfate|Calcium Carbonate|Calcium Acetate|Calcium Gluconate|bumetanide|furosemide|norepinephrine|propofol|fentanyl citrate|dopamine|Fentanyl'\n",
    "emar_medications = ['Magnesium Sulfate',\n",
    "                    'Propofol', 'Fentanyl Citrate', 'NORepinephrine','Norepinephrine', 'Furosemide',\n",
    "                    'Calcium Carbonate', 'Calcium Gluconate','Calcium Acetate','Fentanyl',\n",
    "                    'DOPamine', 'Bumetanide','Calcium Carbonate Suspension',\n",
    "                    'furosemide', 'fentaNYL citrate', ]\n",
    "\n",
    "not_wanted_events = [ 'Not Started', 'Stopped - Unscheduled',\n",
    "       'Not Given', 'Delayed Stopped',\n",
    "       'Delayed Not Started', 'Delayed Not Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = pd.read_csv(path+\"hosp/csv/emar.csv\",sep=',')\n",
    "df_emar = df_emar[~df_emar.event_txt.isin(not_wanted_events)]\n",
    "df_emar = df_emar[df_emar.medication.isin(emar_medications)][['subject_id', 'hadm_id', 'emar_id',\n",
    "       'charttime', 'medication', 'scheduletime', 'storetime']]\n",
    "df_emar.loc[df_emar.medication==\"Norepinephrine\",\"medication\"]='NORepinephrine'\n",
    "df_emar.to_csv(\"Data/MIMIC_extracted/emar_extracted.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = pd.read_csv(\"Data/MIMIC_extracted/emar_extracted.csv\")\n",
    "df_emar_detail = None\n",
    "\n",
    "for chunk in tqdm.tqdm(pd.read_csv(path+\"hosp/csv/emar_detail.csv\",sep=',',\n",
    "                             chunksize=10000000, \n",
    "                             iterator=True,low_memory=False),ascii=True):\n",
    "        \n",
    "        if df_emar_detail is not None :\n",
    "            df_emar_detail = df_emar_detail.append(chunk[chunk.emar_id.isin(df_emar.emar_id.unique())])\n",
    "        else:\n",
    "            df_emar_detail = chunk[chunk.emar_id.isin(df_emar.emar_id.unique())]\n",
    "            \n",
    "    \n",
    "df_emar_detail = df_emar_detail\n",
    "df_emar_detail = df_emar_detail[~df_emar_detail.dose_given.isna()]\n",
    "df_emar_detail.to_csv(\"Data/MIMIC_extracted/emar_detail_extracted.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = pd.read_csv(\"Data/MIMIC_extracted/emar_extracted.csv\")\n",
    "df_emar_detail = pd.read_csv(\"Data/MIMIC_extracted/emar_detail_extracted.csv\")\n",
    "df_AF_medication = df_emar.merge(df_emar_detail,on=[\"subject_id\",\"emar_id\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AF_medication.medication.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = pd.read_csv(path+\"hosp/csv/emar.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icustay = pd.read_csv(path+\"icu/csv/icustays.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = df_emar[df_emar.subject_id.isin(df_icustay.subject_id)]\n",
    "emar_meds_ser = pd.Series(df_emar.medication.value_counts()).reset_index()\n",
    "emar_meds_ser = emar_meds_ser.rename(columns={\"index\":\"medication\",\"medication\":\"count\"})\n",
    "\n",
    "emar_meds_ser[(~emar_meds_ser.medication.isna()) & (emar_meds_ser.medication.str.contains(\"amida\",flags=re.IGNORECASE,regex=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AF_medication[df_AF_medication.medication.str.contains(\"nor\",flags=re.IGNORECASE,regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AF_medication.to_csv(\"Data/MIMIC_extracted/df_AF_medication.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AF_medication = pd.read_csv(path+\"hosp/csv/df_AF_medication.csv\")\n",
    "df_nor = pd.read_csv(path+\"mimic_norepinephrine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_nor.stay_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_AF_medication[df_AF_medication.medication.str.contains(\"NORepine\")].hadm_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import amsterdamumcdb as adb\n",
    "dictionary = adb.get_dictionary()\n",
    "dictionary[dictionary.item.str.contains(\"fenta\",flags=re.IGNORECASE,regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/hosp/csv/emar.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = df_emar[df_emar.subject_id.isin(df_icustay.subject_id)]\n",
    "emar_meds_ser = pd.Series(df_emar.medication.value_counts()).reset_index()\n",
    "emar_meds_ser = emar_meds_ser.rename(columns={\"index\":\"medication\",\"medication\":\"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emar_meds_ser[(~emar_meds_ser.medication.isna()) & (emar_meds_ser.medication.str.contains(\"nore\",flags=re.IGNORECASE,regex=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_items = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/icu/csv/d_items.csv\",sep=',')\n",
    "df_d_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_items[(df_d_items.label.str.contains(r'NOR',flags=re.IGNORECASE, regex=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_items[(df_d_items.label.str.contains('SOFA',flags=re.IGNORECASE, regex=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_labitems = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/hosp/csv/d_labitems.csv\",sep=',')\n",
    "df_d_labitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_labitems[(~df_d_labitems.label.isnull())&(df_d_labitems.label.str.contains(\"urea\",flags=re.IGNORECASE, regex=True))]\n",
    "#df_d_labitems[(~df_d_labitems.label.isnull())&(df_d_labitems.fluid.str.contains(\"Blood\"))&(df_d_labitems.category.str.contains(\"Hematology\"))][240:290]#&(df_d_labitems.label.str.contains(\"lets\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AF patients preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AF = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/AF.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/core/csv/admissions.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icustay = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/icu/csv/icustays.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create admissioncount\n",
    "df_icustay.intime = pd.to_datetime(df_icustay.intime)\n",
    "df_icustay = df_icustay.sort_values([\"subject_id\",\"intime\"]).reset_index(drop=True)\n",
    "df_icustay[\"admissioncount\"]=0\n",
    "for i in range(len(df_icustay)):\n",
    "    if i > 0:\n",
    "        if df_icustay.iloc[i][\"subject_id\"] == df_icustay.iloc[i-1][\"subject_id\"]:\n",
    "            df_icustay.loc[df_icustay.index==i,\"admissioncount\"]=df_icustay.iloc[i-1][\"admissioncount\"]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/core/csv/patients.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_hadm = df_AF.merge(df_adm[df_adm.subject_id.isin(df_icustay.subject_id.unique())],on=['hadm_id',\"subject_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_hadm[\"diff_to_adm\"] = pd.to_datetime(AF_hadm.storetime) - pd.to_datetime(AF_hadm.admittime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm = df_adm.merge(df_icustay,how=\"right\",on=[\"subject_id\",\"hadm_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_AF_episode = df_AF.sort_values([\"hadm_id\",\"stay_id\",\"storetime\"]).groupby(\"stay_id\").first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm[\"AF\"]=0\n",
    "df_adm.loc[df_adm.stay_id.isin(patient_AF_episode.stay_id.unique()),\"AF\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm[\"AF\"]=0\n",
    "df_adm.loc[df_adm.stay_id.isin(patient_AF_episode.stay_id.unique()),\"AF\"]=1\n",
    "\n",
    "df_adm[\"AF_measuredat\"] = 0\n",
    "for stay_id in patient_AF_episode.stay_id.unique():\n",
    "    df_adm.loc[df_adm.stay_id==stay_id,\"AF_measuredat\"]=patient_AF_episode[patient_AF_episode.stay_id==stay_id].storetime.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm[df_adm.AF==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_onset_pat = AF_hadm[AF_hadm.diff_to_adm<pd.to_timedelta(12,unit='h')].subject_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diag = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/hosp/csv/diagnoses_icd.csv\",sep=',')\n",
    "df_proced = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/hosp/csv/procedures_icd.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_services[df_services.curr_service.str.contains(\"CSURG\")].hadm_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diag_icd = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/hosp/csv/d_icd_diagnoses.csv\",sep=',')\n",
    "df_proced_icd = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/hosp/csv/d_icd_procedures.csv\",sep=',')\n",
    "\n",
    "re_cardiosurg_new = (\n",
    "    r'(CABG|AVR|heart surgery|cardiovascular disease|heart valves|'\n",
    "    r'MVP|MVR|mitral|tricuspid|pericard|aortic.*valve|Bentall|'\n",
    "    r'myocardial infarcation|VSR|ASD|intracardiac|congenital defect repair)(?! for esophag)'\n",
    ")\n",
    "\n",
    "re_sepsis_surg = r'sepsis|pneumoni|GI perforation|perforation|rupture|infection|abscess|GI Vascular ischemia|diverticular|appendectomy|peritonitis'\n",
    "re_sepsis_med = r'sepsis|septic|infect|pneumoni|cholangitis|pancr|endocarditis|meningitis|GI perforation|abces|abscess|colon ischemi|GI vascular|fasciitis|inflammatory|peritonitis'\n",
    "\n",
    "\n",
    "surg_icds = df_proced_icd[df_proced_icd.long_title.str.contains(\"surgery|surg\", na=False,flags=re.IGNORECASE,regex=True)].icd_code\n",
    "card_icds = df_diag_icd[df_diag_icd.long_title.str.contains(re_cardiosurg_new, na=False,flags=re.IGNORECASE,regex=True)].icd_code\n",
    "seps = df_diag_icd[df_diag_icd.long_title.str.contains(\"sepsis|seps\", na=False,flags=re.IGNORECASE,regex=True)].icd_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_hadms = df_diag[(df_diag.icd_code.isin(card_icds))].hadm_id.unique()\n",
    "#surg_hadms = df_diag[(df_diag.icd_code.isin(surg_icds))].hadm_id.unique()\n",
    "surg_hadms = df_diag[(df_diag.icd_code.isin(surg_icds))].hadm_id.unique()\n",
    "seps_hadms = df_diag[(df_diag.icd_code.isin(seps))].hadm_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_services = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/hosp/csv/services.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_services[df_services.hadm_id==29988601]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_hadms = df_services[df_services.curr_service.str.contains(r\"CMED|CSURG\",regex=True)].hadm_id.unique()\n",
    "surg_hadms = df_services[df_services.curr_service.str.contains(r\"NSURG|CSURG|PSURG|SURG|TSURG|VSURG\",regex=True)].hadm_id.unique()\n",
    "medical_hadms = df_services[df_services.curr_service.str.contains(r\"CMED|MED|NMED|OMED|PSYCH\",regex=True)].hadm_id.unique()\n",
    "df_sepsis3 = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/mimic_sepsis3.csv\",sep=',')\n",
    "seps_hadms = df_sepsis3.stay_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm[(df_adm.hadm_id.isin(medical_hadms))&(df_adm.hadm_id.isin(surg_hadms))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm[\"sepsis_bool\"] = 0\n",
    "df_adm.loc[df_adm.stay_id.isin(seps_hadms),\"sepsis_bool\"]=1\n",
    "\n",
    "df_adm[\"surgery_bool\"] = 0 \n",
    "df_adm.loc[df_adm.hadm_id.isin(surg_hadms),\"surgery_bool\"]=1\n",
    "\n",
    "df_adm[\"cardiac_bool\"] = 0\n",
    "df_adm.loc[df_adm.hadm_id.isin(card_hadms),\"cardiac_bool\"]=1\n",
    "\n",
    "df_adm[\"medical_bool\"] = 0\n",
    "df_adm.loc[df_adm.hadm_id.isin(medical_hadms),\"medical_bool\"]=1\n",
    "\n",
    "df_adm[\"cardiac_bool_new\"] = 0\n",
    "df_adm.loc[(df_adm.cardiac_bool==1) & (df_adm.surgery_bool ==1),\"cardiac_bool_new\" ]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm[(df_adm.subject_id.isin(df_icustay.subject_id.unique()))].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/core/csv/patients.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm_icu = df_adm[(df_adm.subject_id.isin(df_icustay.subject_id.unique()))]\n",
    "df_adm_icu.to_csv(\"Data/MIMIC/mimic-iv-1.0/df_adm_icu.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm_icu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm_af = pd.read_csv(\"Data/MIMIC/mimic-iv-1.0/df_adm_icu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_adm_af[df_adm_af.AF==0].hospital_expire_flag,density=True,label=\"NO AF\")\n",
    "plt.hist(df_adm_af[df_adm_af.AF==1].hospital_expire_flag,density=True,label=\"AF\",alpha=0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_adm_af[df_adm_af.AF==0].los,density=True,label=\"NO AF\",bins=np.arange(0,50,2))\n",
    "plt.hist(df_adm_af[df_adm_af.AF==1].los,density=True,label=\"AF\",alpha=0.5,bins=np.arange(0,50,2))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_items = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/icu/csv/d_items.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_items[df_d_items.label.str.contains(\"vanco\",flags=re.IGNORECASE,regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputevents = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/icu/csv/inputevents.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp_vanco = df_inputevents[df_inputevents.itemid==225798]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp_vanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_labitems = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/hosp/csv/d_labitems.csv\",sep=',')\n",
    "df_d_labitems.label = df_d_labitems.label.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_labitems[df_d_labitems.label.str.contains(\"vanco\",flags=re.IGNORECASE,regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vanco = pd.read_csv(r\"Data/MIMIC/mimic-iv-1.0/hosp/csv/labevents/51009.csv\",sep=',',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vanco"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "Start executing here to get the relevent datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "plt.rcParams[\"axes.grid\"] = False #disable ugly white lines which are present in google colab for matplotlib\n",
    "import numpy as np\n",
    "import datetime\n",
    "today = datetime.datetime.today() #To work with datetime values. Only relative time matters in this project, so selecting a random date is not a problem. \n",
    "from sklearn.metrics import classification_report,auc,r2_score,matthews_corrcoef\n",
    "import shap\n",
    "from catboost import CatBoostClassifier,CatBoostRegressor,Pool\n",
    "from catboost.utils import get_roc_curve\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from scipy.stats import linregress,ttest_ind,ranksums\n",
    "mimic_extracted_path = \"../../IC_DC_AF/Data/MIMIC_extracted/\"\n",
    "mimic_base_path = \"../../../MIMIC_IV/mimic-iv-1.0/\"\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admission and patient preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_pd = pd.read_csv(mimic_extracted_path+\"df_adm_icu.csv\",sep=',')\n",
    "admissions_pd = admissions_pd[['subject_id', 'hadm_id', 'admittime', 'AF', 'AF_measuredat','intime','outtime',\n",
    "       'sepsis_bool', 'surgery_bool', 'cardiac_bool', 'cardiac_bool_new',\n",
    "       'stay_id', 'los', 'admissioncount']]\n",
    "admissions_pd = admissions_pd.rename(columns={\"subject_id\":\"patientid\",\"stay_id\":\"admissionid\",\"los\":\"lengthofstay\"})\n",
    "admissions_pd.loc[:,\"intime\"] = pd.to_datetime(admissions_pd.intime)\n",
    "admissions_pd.loc[:,\"outtime\"] = pd.to_datetime(admissions_pd.outtime)\n",
    "admissions_pd.loc[:,\"lengthofstay\"]=admissions_pd.lengthofstay*24\n",
    "admissions_pd.loc[admissions_pd.AF_measuredat==\"0\",\"AF_measuredat\"]=0\n",
    "admissions_pd.loc[admissions_pd.AF_measuredat!=0,\"AF_measuredat\"]=(pd.to_datetime(admissions_pd[admissions_pd.AF_measuredat!=0].AF_measuredat)-pd.to_datetime(admissions_pd[admissions_pd.AF_measuredat!=0].intime)).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False\n",
    "#True\n",
    "\n",
    "one_half_hour_model = True\n",
    "non_biased_model = False #Match the NO AF measurement point distribution to the AF patients to avoid time-dependent treatment bias\n",
    "six_hour_model = False\n",
    "\n",
    "if one_half_hour_model:\n",
    "    time_shift = 1.5\n",
    "    margin_time = 1.5\n",
    "else:\n",
    "    time_shift = 12\n",
    "    margin_time = 0\n",
    "\n",
    "if six_hour_model:\n",
    "    time_shift = 6\n",
    "    margin_time = 0\n",
    "    \n",
    "hours_to_first_AF = 12\n",
    "total_window = hours_to_first_AF+time_shift\n",
    "total_window\n",
    "\n",
    "to_hour_multiplier = 60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_data_of_first_hours = False #Use only data of the first X hours of admission\n",
    "\n",
    "total_window = hours_to_first_AF+time_shift\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "admission_pd_min_hour = admissions_pd[(admissions_pd.lengthofstay>=total_window)].copy(deep=True)\n",
    "\n",
    "admission_pd_min_hour = admission_pd_min_hour.sample(len(admission_pd_min_hour),random_state=42)\n",
    "admission_pd_min_hour = admission_pd_min_hour[(admission_pd_min_hour.AF==0)|(admission_pd_min_hour.AF_measuredat>=to_hour_multiplier*total_window)]\n",
    "\n",
    "if non_biased_model:\n",
    "    AF_measuredat_sample_df = admission_pd_min_hour[(admission_pd_min_hour.AF==1)&(admission_pd_min_hour.AF_measuredat>to_hour_multiplier*(total_window))][[\"admissionid\",\"AF_measuredat\"]].copy(deep=True)\n",
    "    admission_pd_min_hour[\"date_corresponds_to_AF_admid\"] = admission_pd_min_hour.admissionid\n",
    "    for admissionid in admission_pd_min_hour[admission_pd_min_hour.AF==0].admissionid.values:\n",
    "        if len(AF_measuredat_sample_df) == 0:\n",
    "            break\n",
    "        else:\n",
    "            if len(AF_measuredat_sample_df[AF_measuredat_sample_df.AF_measuredat<=((admission_pd_min_hour[admission_pd_min_hour.admissionid==admissionid]['lengthofstay'].values[0])*to_hour_multiplier)])>0:\n",
    "                random_state_admission = np.random.RandomState(admissionid)\n",
    "                choice = random_state_admission.choice(AF_measuredat_sample_df[AF_measuredat_sample_df.AF_measuredat<=((admission_pd_min_hour[admission_pd_min_hour.admissionid==admissionid]['lengthofstay'].values[0]+0.1)*to_hour_multiplier)]['admissionid'].values)\n",
    "                admission_pd_min_hour.loc[admission_pd_min_hour.admissionid==admissionid,\"AF_measuredat\"] = AF_measuredat_sample_df[AF_measuredat_sample_df.admissionid==choice].AF_measuredat.values[0]\n",
    "                admission_pd_min_hour.loc[admission_pd_min_hour.admissionid==admissionid,\"date_corresponds_to_AF_admid\"] = AF_measuredat_sample_df[AF_measuredat_sample_df.admissionid==choice].admissionid.values[0]\n",
    "                AF_measuredat_sample_df = AF_measuredat_sample_df[AF_measuredat_sample_df.admissionid!=choice]   \n",
    "    admission_pd_min_hour.loc[:,\"AF_measuredat\"] = admission_pd_min_hour.apply(lambda row: to_hour_multiplier*np.random.randint(total_window,row['lengthofstay']+1) if ((row['AF']==0)&((row['AF_measuredat'] == 0)|( pd.isnull(row['AF_measuredat'])))) else row['AF_measuredat'],axis=1).values \n",
    "\n",
    "else:\n",
    "    admission_pd_min_hour.loc[:,\"AF_measuredat\"] = admission_pd_min_hour.apply(lambda row: to_hour_multiplier*np.random.randint(total_window,row['lengthofstay']+1) if ((row['AF']==0)&((row['AF_measuredat'] == 0)|( pd.isnull(row['AF_measuredat'])))) else row['AF_measuredat'],axis=1).values \n",
    "\n",
    "\n",
    "\n",
    "admission_pd_min_hour[\"AF_orig\"]=admission_pd_min_hour.AF\n",
    "AF_admission_dataset = admission_pd_min_hour[admission_pd_min_hour.AF_measuredat>=total_window*to_hour_multiplier]\n",
    "\n",
    "first_AFs_pd_timed = None\n",
    "temp_pd = None\n",
    "admission_pd_min_hour = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction chartitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg_except(x,value,measuredat):\n",
    "    try:\n",
    "        return linregress(x[measuredat],x[value])[0]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "numeric_items_pd = pd.read_csv(mimic_extracted_path+\"chart_items_af_features.csv\",sep=',')\n",
    "numeric_items_pd.loc[:,\"value\"]=numeric_items_pd.valuenum\n",
    "numeric_items_pd = numeric_items_pd.rename(columns={\"storetime\":\"measuredat\",\"stay_id\":\"admissionid\",\"subject_id\":\"patientid\"})\n",
    "numeric_items_pd = numeric_items_pd[['patientid', 'admissionid', 'measuredat', 'itemid', 'value']]\n",
    "\n",
    "df_d_items = pd.read_csv(mimic_base_path+\"icu/csv/d_items.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERIC ITEMS PREPROCESSING, this takes around 2 minutes\n",
    "if non_biased_model:\n",
    "    numeric_pd_patients = (numeric_items_pd[numeric_items_pd.admissionid.isin(AF_admission_dataset.admissionid)]).merge(AF_admission_dataset[[\"admissionid\",\"AF_measuredat\",\"date_corresponds_to_AF_admid\",\"intime\"]],how='left',on='admissionid')\n",
    "else:\n",
    "    numeric_pd_patients = (numeric_items_pd[numeric_items_pd.admissionid.isin(AF_admission_dataset.admissionid)]).merge(AF_admission_dataset[[\"admissionid\",\"AF_measuredat\",\"intime\"]],how='left',on='admissionid')\n",
    "\n",
    "#MIMIC specific preprocessing\n",
    "numeric_pd_patients.loc[:,\"measuredat\"]=(pd.to_datetime(numeric_pd_patients.measuredat)-numeric_pd_patients.intime).dt.total_seconds() #INTIME is already in datetime\n",
    "numeric_pd_patients[\"measuredat_min\"] = np.floor(numeric_pd_patients.measuredat/60) #per minute\n",
    "numeric_pd_patients = numeric_pd_patients.drop(columns=[\"intime\"])\n",
    "\n",
    "numeric_pd_patients[\"time_to_AF\"]=(numeric_pd_patients.AF_measuredat.values-60*60*margin_time) - numeric_pd_patients.measuredat.values #add one margin_time to AF extra\n",
    "numeric_pd_patients = numeric_pd_patients[(numeric_pd_patients.time_to_AF > (time_shift-margin_time)*60*60) & (numeric_pd_patients.time_to_AF/60/60 <= (time_shift+hours_to_first_AF-margin_time-1) )]\n",
    "\n",
    "for itemid_loop in numeric_items_pd.itemid.unique():\n",
    "    numeric_pd_patients.itemid = numeric_pd_patients.itemid.replace(itemid_loop,df_d_items[df_d_items.itemid==itemid_loop].label.values[0])\n",
    "\n",
    "numeric_items_pd = None #RAM Optimization\n",
    "\n",
    "numeric_pd_patients_agg = numeric_pd_patients[[\"admissionid\",\"itemid\",\"value\"]].groupby([\"admissionid\",\"itemid\"]).agg({'mean','min','max',pd.DataFrame.kurt}).reset_index()\n",
    "numeric_pd_patients_agg.itemid = numeric_pd_patients_agg.itemid.astype(str)\n",
    "numeric_pd_patients_agg.columns = ['_'.join(col).rstrip('_') for col in numeric_pd_patients_agg.columns.values]\n",
    "numeric_pd_patients_agg.columns = [col.replace('value_','') if 'value_' in col else col for col in numeric_pd_patients_agg.columns.values]\n",
    "numeric_pd_patients_agg = numeric_pd_patients_agg.pivot(index='admissionid', columns='itemid')\n",
    "numeric_pd_patients_agg.columns = ['_'.join(col).rstrip('_') for col in numeric_pd_patients_agg.columns.values]\n",
    "\n",
    "\n",
    "\n",
    "numeric_pd_patients_slope = numeric_pd_patients[[\"admissionid\",\"itemid\",\"measuredat_min\",\"value\"]].groupby([\"admissionid\",\"itemid\"]).apply(lambda x:linreg_except(x,\"value\",\"measuredat_min\")).reset_index()\n",
    "numeric_pd_patients_slope.columns = [str(col) for col in numeric_pd_patients_slope.columns.values]\n",
    "numeric_pd_patients_slope = numeric_pd_patients_slope.rename(columns={'0':\"slope\"})\n",
    "numeric_pd_patients_slope.itemid = numeric_pd_patients_slope.itemid.astype(str)\n",
    "numeric_pd_patients_slope = numeric_pd_patients_slope.pivot(index='admissionid', columns='itemid')\n",
    "numeric_pd_patients_slope.columns = ['_'.join(col).rstrip('_') for col in numeric_pd_patients_slope.columns.values]\n",
    "numeric_pd_patients_slope = numeric_pd_patients_slope.reset_index()\n",
    "\n",
    "numeric_pd_patients_total = numeric_pd_patients_agg.merge(numeric_pd_patients_slope,how='left',on='admissionid')\n",
    "numeric_pd_patients = None #Save RAM\n",
    "numeric_pd_patients_slope = None\n",
    "numeric_pd_patients_agg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction Labitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_items_af_features = pd.read_csv(mimic_extracted_path+\"lab_items_af_features.csv\",sep=',')\n",
    "lab_items_af_features = lab_items_af_features[lab_items_af_features.subject_id.isin(AF_admission_dataset.patientid.values)].reset_index(drop=True)\n",
    "lab_items_af_features.loc[:,\"storetime\"]=pd.to_datetime(lab_items_af_features.storetime)\n",
    "lab_items_af_features.loc[:,\"value\"]=lab_items_af_features.valuenum\n",
    "lab_items_af_features = lab_items_af_features.rename(columns={\"subject_id\":\"patientid\",\"storetime\":\"measuredat\"})\n",
    "\n",
    "df_d_labitems = pd.read_csv(mimic_base_path+\"hosp/csv/d_labitems.csv\",sep=',')\n",
    "lab_items_af_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_items_patients = lab_items_af_features.merge(AF_admission_dataset,how=\"left\",on=\"patientid\")\n",
    "lab_items_patients = lab_items_patients[(lab_items_patients.measuredat>=lab_items_patients.intime)&(lab_items_patients.measuredat<=lab_items_patients.outtime)]\n",
    "\n",
    "#MIMIC specific preprocessing\n",
    "lab_items_patients.loc[:,\"measuredat\"]=(pd.to_datetime(lab_items_patients.measuredat)-lab_items_patients.intime).dt.total_seconds() #INTIME is already in datetime\n",
    "lab_items_patients[\"measuredat_min\"] = np.floor(lab_items_patients.measuredat/60) #per minute\n",
    "lab_items_patients = lab_items_patients.drop(columns=[\"intime\",\"outtime\"])\n",
    "\n",
    "lab_items_patients[\"time_to_AF\"]=(lab_items_patients.AF_measuredat.values-60*60*margin_time) - lab_items_patients.measuredat.values #add one margin_time to AF extra\n",
    "lab_items_patients = lab_items_patients[(lab_items_patients.time_to_AF > (time_shift-margin_time)*60*60) & (lab_items_patients.time_to_AF/60/60 <= (time_shift+hours_to_first_AF-margin_time-1) )]\n",
    "\n",
    "for itemid_loop in lab_items_af_features.itemid.unique():\n",
    "    lab_items_patients.itemid = lab_items_patients.itemid.replace(itemid_loop,df_d_labitems[df_d_labitems.itemid==itemid_loop].label.values[0])\n",
    "\n",
    "lab_items_af_features = None #RAM Optimization\n",
    "\n",
    "lab_items_patients_agg = lab_items_patients[[\"admissionid\",\"itemid\",\"value\"]].groupby([\"admissionid\",\"itemid\"]).agg({'mean','min','max',pd.DataFrame.kurt}).reset_index()\n",
    "lab_items_patients_agg.itemid = lab_items_patients_agg.itemid.astype(str)\n",
    "lab_items_patients_agg.columns = ['_'.join(col).rstrip('_') for col in lab_items_patients_agg.columns.values]\n",
    "lab_items_patients_agg.columns = [col.replace('value_','') if 'value_' in col else col for col in lab_items_patients_agg.columns.values]\n",
    "lab_items_patients_agg = lab_items_patients_agg.pivot(index='admissionid', columns='itemid')\n",
    "lab_items_patients_agg.columns = ['_'.join(col).rstrip('_') for col in lab_items_patients_agg.columns.values]\n",
    "\n",
    "lab_items_patients_slope = lab_items_patients[[\"admissionid\",\"itemid\",\"measuredat_min\",\"value\"]].groupby([\"admissionid\",\"itemid\"]).apply(lambda x:linreg_except(x,\"value\",\"measuredat_min\")).reset_index()\n",
    "lab_items_patients_slope.columns = [str(col) for col in lab_items_patients_slope.columns.values]\n",
    "lab_items_patients_slope = lab_items_patients_slope.rename(columns={'0':\"slope\"})\n",
    "lab_items_patients_slope.itemid = lab_items_patients_slope.itemid.astype(str)\n",
    "lab_items_patients_slope = lab_items_patients_slope.pivot(index='admissionid', columns='itemid')\n",
    "lab_items_patients_slope.columns = ['_'.join(col).rstrip('_') for col in lab_items_patients_slope.columns.values]\n",
    "lab_items_patients_slope = lab_items_patients_slope.reset_index()\n",
    "\n",
    "lab_items_patients_total = lab_items_patients_agg.merge(lab_items_patients_slope,how='left',on='admissionid')\n",
    "lab_items_patients = None #Save RAM\n",
    "lab_items_patients_slope = None\n",
    "lab_items_patients_agg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_items_patients_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction Medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AF_medication = pd.read_csv(mimic_extracted_path+\"df_AF_medication.csv\",sep=',')\n",
    "\n",
    "df_AF_medication.loc[:,\"storetime\"] = pd.to_datetime(df_AF_medication.storetime)\n",
    "df_AF_medication = df_AF_medication.rename(columns={\"storetime\":\"measuredat\",\"dose_given\":\"value\",\"subject_id\":\"patientid\"})\n",
    "df_AF_medication.loc[df_AF_medication.value.isna(),\"dose_given_unit\"] = \"Missing\"\n",
    "df_AF_medication.loc[:,\"value\"] = df_AF_medication.value.fillna(\"1\")\n",
    "df_AF_medication.loc[:,\"value\"] = str(df_AF_medication.value)\n",
    "df_AF_medication = df_AF_medication[df_AF_medication.value.str.contains(\"\\d+\",regex=True)]\n",
    "df_AF_medication.loc[:,\"value\"] = df_AF_medication.value.str.extract(r'(\\d+)',expand=False)\n",
    "df_AF_medication.value = df_AF_medication.value.astype(np.float32)\n",
    "df_AF_medication = df_AF_medication[(df_AF_medication.medication!=\"Magnesium Sulfate\") | ((df_AF_medication.medication==\"Magnesium Sulfate\")&(df_AF_medication.dose_given_unit.isin([\"Missing\",\"gm\"])))]\n",
    "df_AF_medication = df_AF_medication[(df_AF_medication.medication!=\"Propofol\") | ((df_AF_medication.medication==\"Propofol\")&(df_AF_medication.dose_given_unit.isin([\"Missing\",\"mg\"])))]\n",
    "df_AF_medication = df_AF_medication[(df_AF_medication.medication!=\"Fentanyl Citrate\") | ((df_AF_medication.medication==\"Fentanyl Citrate\")&(df_AF_medication.dose_given_unit.isin([\"Missing\",\"mcg\"])))]\n",
    "df_AF_medication = df_AF_medication[(df_AF_medication.medication!=\"Calcium Carbonate\") | ((df_AF_medication.medication==\"Calcium Carbonate\")&(df_AF_medication.dose_given_unit.isin([\"Missing\",\"mg\"])))]\n",
    "df_AF_medication = df_AF_medication[(df_AF_medication.medication!=\"Calcium Gluconate\") | ((df_AF_medication.medication==\"Calcium Gluconate\")&(~df_AF_medication.dose_given_unit.isin([\"mg\"])))]\n",
    "\n",
    "\n",
    "#unit correction\n",
    "#does not actually matter, as only \"is given\" will be used\n",
    "\n",
    "df_AF_medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medication_patients = df_AF_medication.merge(AF_admission_dataset,how=\"left\",on=\"patientid\")\n",
    "medication_patients = medication_patients[(medication_patients.measuredat>=medication_patients.intime)&(medication_patients.measuredat<=medication_patients.outtime)]\n",
    "\n",
    "#MIMIC specific preprocessing\n",
    "medication_patients.loc[:,\"measuredat\"]=(pd.to_datetime(medication_patients.measuredat)-medication_patients.intime).dt.total_seconds() #INTIME is already in datetime\n",
    "medication_patients[\"measuredat_min\"] = np.floor(medication_patients.measuredat/60) #per minute\n",
    "medication_patients = medication_patients.drop(columns=[\"intime\",\"outtime\"])\n",
    "\n",
    "medication_patients[\"time_to_AF\"]=(medication_patients.AF_measuredat.values-60*60*margin_time) - medication_patients.measuredat.values #add one margin_time to AF extra\n",
    "medication_patients = medication_patients[(medication_patients.time_to_AF > (time_shift-margin_time)*60*60) & (medication_patients.time_to_AF/60/60 <= (time_shift+hours_to_first_AF-margin_time-1) )]\n",
    "\n",
    "medication_patients[\"itemid\"] = medication_patients.medication\n",
    "\n",
    "df_AF_medication = None #RAM Optimization\n",
    "\n",
    "medication_patients_agg = medication_patients[[\"admissionid\",\"itemid\",\"value\"]].groupby([\"admissionid\",\"itemid\"]).agg({'mean','min','max',pd.DataFrame.kurt}).reset_index()\n",
    "medication_patients_agg.itemid = medication_patients_agg.itemid.astype(str)\n",
    "medication_patients_agg.columns = ['_'.join(col).rstrip('_') for col in medication_patients_agg.columns.values]\n",
    "medication_patients_agg.columns = [col.replace('value_','') if 'value_' in col else col for col in medication_patients_agg.columns.values]\n",
    "medication_patients_agg = medication_patients_agg.pivot(index='admissionid', columns='itemid')\n",
    "medication_patients_agg.columns = ['_'.join(col).rstrip('_') for col in medication_patients_agg.columns.values]\n",
    "\n",
    "medication_patients_slope = medication_patients[[\"admissionid\",\"itemid\",\"measuredat_min\",\"value\"]].groupby([\"admissionid\",\"itemid\"]).apply(lambda x:linreg_except(x,\"value\",\"measuredat_min\")).reset_index()\n",
    "medication_patients_slope.columns = [str(col) for col in medication_patients_slope.columns.values]\n",
    "medication_patients_slope = medication_patients_slope.rename(columns={'0':\"slope\"})\n",
    "medication_patients_slope.itemid = medication_patients_slope.itemid.astype(str)\n",
    "medication_patients_slope = medication_patients_slope.pivot(index='admissionid', columns='itemid')\n",
    "medication_patients_slope.columns = ['_'.join(col).rstrip('_') for col in medication_patients_slope.columns.values]\n",
    "medication_patients_slope = medication_patients_slope.reset_index()\n",
    "\n",
    "medication_patients_total_emar = medication_patients_agg.merge(medication_patients_slope,how='left',on='admissionid')\n",
    "medication_patients = None #Save RAM\n",
    "medication_patients_slope = None\n",
    "medication_patients_agg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emar_features = ['admissionid', 'kurt_Calcium Acetate',\n",
    "       'kurt_Calcium Carbonate', 'kurt_Calcium Carbonate Suspension',\n",
    "       'kurt_Fentanyl Citrate',\n",
    "     'kurt_Calcium Gluconate',\n",
    "     'mean_Calcium Acetate',\n",
    "       'mean_Calcium Carbonate', 'mean_Calcium Carbonate Suspension',\n",
    "       'mean_Calcium Gluconate',  'mean_Fentanyl Citrate',\n",
    "        'max_Calcium Acetate',\n",
    "       'max_Calcium Carbonate', 'max_Calcium Carbonate Suspension',\n",
    "       'max_Calcium Gluconate', 'max_Fentanyl Citrate',\n",
    "        'min_Calcium Acetate',\n",
    "       'min_Calcium Carbonate', 'min_Calcium Carbonate Suspension',\n",
    "       'min_Calcium Gluconate',  'min_Fentanyl Citrate',\n",
    "      'slope_Calcium Acetate',\n",
    "       'slope_Calcium Carbonate', 'slope_Calcium Carbonate Suspension',\n",
    "       'slope_Calcium Gluconate',  'slope_Fentanyl Citrate'\n",
    "       ]\n",
    "\n",
    "medication_patients_total = medication_patients_total_emar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medication_patients_total.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_af_features = pd.read_csv(mimic_extracted_path+\"output_af_features.csv\",sep=',')\n",
    "output_af_features = output_af_features.rename(columns={\"storetime\":\"measuredat\",\"subject_id\":\"patientid\",\"stay_id\":\"admissionid\"})\n",
    "output_af_features.measuredat = pd.to_datetime(output_af_features.measuredat)\n",
    "\n",
    "\n",
    "df_d_items = pd.read_csv(mimic_base_path+\"icu/csv/d_items.csv\",sep=',')\n",
    "\n",
    "output_af_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERIC ITEMS PREPROCESSING, this takes around 2 minutes\n",
    "if non_biased_model:\n",
    "    output_pd_patients = (output_af_features[output_af_features.admissionid.isin(AF_admission_dataset.admissionid)]).merge(AF_admission_dataset[[\"admissionid\",\"AF_measuredat\",\"date_corresponds_to_AF_admid\",\"intime\"]],how='left',on='admissionid')\n",
    "else:\n",
    "    output_pd_patients = (output_af_features[output_af_features.admissionid.isin(AF_admission_dataset.admissionid)]).merge(AF_admission_dataset[[\"admissionid\",\"AF_measuredat\",\"intime\"]],how='left',on='admissionid')\n",
    "\n",
    "#MIMIC specific preprocessing\n",
    "output_pd_patients.loc[:,\"measuredat\"]=(pd.to_datetime(output_pd_patients.measuredat)-output_pd_patients.intime).dt.total_seconds() #INTIME is already in datetime\n",
    "output_pd_patients[\"measuredat_min\"] = np.floor(output_pd_patients.measuredat/60) #per minute\n",
    "output_pd_patients = output_pd_patients.drop(columns=[\"intime\"])\n",
    "\n",
    "output_pd_patients[\"time_to_AF\"]=(output_pd_patients.AF_measuredat.values-60*60*margin_time) - output_pd_patients.measuredat.values #add one margin_time to AF extra\n",
    "output_pd_patients = output_pd_patients[(output_pd_patients.time_to_AF > (time_shift-margin_time)*60*60) & (output_pd_patients.time_to_AF/60/60 <= (time_shift+hours_to_first_AF-margin_time-1) )]\n",
    "\n",
    "for itemid_loop in output_af_features.itemid.unique():\n",
    "    output_pd_patients.itemid = output_pd_patients.itemid.replace(itemid_loop,df_d_items[df_d_items.itemid==itemid_loop].label.values[0])\n",
    "\n",
    "output_af_features = None #RAM Optimization\n",
    "\n",
    "output_pd_patients_agg = output_pd_patients[[\"admissionid\",\"itemid\",\"value\"]].groupby([\"admissionid\",\"itemid\"]).agg({'mean','min','max',pd.DataFrame.kurt}).reset_index()\n",
    "output_pd_patients_agg.itemid = output_pd_patients_agg.itemid.astype(str)\n",
    "output_pd_patients_agg.columns = ['_'.join(col).rstrip('_') for col in output_pd_patients_agg.columns.values]\n",
    "output_pd_patients_agg.columns = [col.replace('value_','') if 'value_' in col else col for col in output_pd_patients_agg.columns.values]\n",
    "output_pd_patients_agg = output_pd_patients_agg.pivot(index='admissionid', columns='itemid')\n",
    "output_pd_patients_agg.columns = ['_'.join(col).rstrip('_') for col in output_pd_patients_agg.columns.values]\n",
    "\n",
    "output_pd_patients_slope = output_pd_patients[[\"admissionid\",\"itemid\",\"measuredat_min\",\"value\"]].groupby([\"admissionid\",\"itemid\"]).apply(lambda x:linreg_except(x,\"value\",\"measuredat_min\")).reset_index()\n",
    "output_pd_patients_slope.columns = [str(col) for col in output_pd_patients_slope.columns.values]\n",
    "output_pd_patients_slope = output_pd_patients_slope.rename(columns={'0':\"slope\"})\n",
    "output_pd_patients_slope.itemid = output_pd_patients_slope.itemid.astype(str)\n",
    "output_pd_patients_slope = output_pd_patients_slope.pivot(index='admissionid', columns='itemid')\n",
    "output_pd_patients_slope.columns = ['_'.join(col).rstrip('_') for col in output_pd_patients_slope.columns.values]\n",
    "output_pd_patients_slope = output_pd_patients_slope.reset_index()\n",
    "\n",
    "output_pd_patients_total = output_pd_patients_agg.merge(output_pd_patients_slope,how='left',on='admissionid')\n",
    "output_pd_patients = None #Save RAM\n",
    "output_pd_patients_slope = None\n",
    "output_pd_patients_agg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluid balance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fluid_af_features = pd.read_csv(mimic_extracted_path+\"input_fluid_af_features.csv\",sep=',')\n",
    "input_fluid_af_features = input_fluid_af_features.rename(columns={\"storetime\":\"measuredat\",\"subject_id\":\"patientid\",\"stay_id\":\"admissionid\",\"amount\":\"fluidin\"})\n",
    "input_fluid_af_features.starttime = pd.to_datetime(input_fluid_af_features.starttime)\n",
    "input_fluid_af_features.endtime = pd.to_datetime(input_fluid_af_features.endtime)\n",
    "\n",
    "outputevents = pd.read_csv(mimic_base_path+\"icu/csv/outputevents.csv\",sep=',')\n",
    "outputevents = outputevents.rename(columns={\"storetime\":\"measuredat\",\"subject_id\":\"patientid\",\"stay_id\":\"admissionid\",\"value\":\"fluidout\"})\n",
    "outputevents.measuredat = pd.to_datetime(outputevents.measuredat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERIC ITEMS PREPROCESSING, this takes around 2 minutes\n",
    "if non_biased_model:\n",
    "    input_fluid_pd_patients = (input_fluid_af_features[input_fluid_af_features.admissionid.isin(AF_admission_dataset.admissionid)]).merge(AF_admission_dataset[[\"admissionid\",\"AF_measuredat\",\"date_corresponds_to_AF_admid\",\"intime\"]],how='left',on='admissionid')\n",
    "else:\n",
    "    input_fluid_pd_patients = (input_fluid_af_features[input_fluid_af_features.admissionid.isin(AF_admission_dataset.admissionid)]).merge(AF_admission_dataset[[\"admissionid\",\"AF_measuredat\",\"intime\"]],how='left',on='admissionid')\n",
    "\n",
    "#MIMIC specific preprocessing\n",
    "input_fluid_pd_patients.loc[:,\"starttime\"]=(pd.to_datetime(input_fluid_pd_patients.starttime)-input_fluid_pd_patients.intime).dt.total_seconds() #INTIME is already in datetime\n",
    "input_fluid_pd_patients.loc[:,\"endtime\"]=(pd.to_datetime(input_fluid_pd_patients.endtime)-input_fluid_pd_patients.intime).dt.total_seconds() #INTIME is already in datetime\n",
    "input_fluid_pd_patients = input_fluid_pd_patients.drop(columns=[\"intime\"])\n",
    "\n",
    "input_fluid_pd_patients[\"start_time_to_AF\"]=(input_fluid_pd_patients.AF_measuredat.values-60*60*margin_time) - input_fluid_pd_patients.starttime.values #add one margin_time to AF extra\n",
    "input_fluid_pd_patients[\"stop_time_to_AF\"]=(input_fluid_pd_patients.AF_measuredat.values-60*60*margin_time) - input_fluid_pd_patients.endtime.values #add one margin_time to AF extra\n",
    "\n",
    "input_fluid_pd_patients = input_fluid_pd_patients[((input_fluid_pd_patients.start_time_to_AF > (time_shift-margin_time)*60*60) & (input_fluid_pd_patients.start_time_to_AF/60/60 <= (time_shift+hours_to_first_AF-margin_time-1) ))|\n",
    "                            ((input_fluid_pd_patients.stop_time_to_AF > (time_shift-margin_time)*60*60) & (input_fluid_pd_patients.stop_time_to_AF/60/60 <= (time_shift+hours_to_first_AF-margin_time-1) ))]\n",
    "\n",
    "output_af_features = None #RAM Optimization\n",
    "\n",
    "input_fluid_pd_patients_agg = input_fluid_pd_patients[[\"admissionid\",\"fluidin\"]].groupby([\"admissionid\"]).sum().reset_index()\n",
    "\n",
    "input_fluid_pd_patients_total = input_fluid_pd_patients_agg\n",
    "input_fluid_pd_patients_agg = None #Save RAM\n",
    "input_fluid_pd_patients = None\n",
    "\n",
    "#NUMERIC ITEMS PREPROCESSING, this takes around 2 minutes\n",
    "if non_biased_model:\n",
    "    output_fluid_pd_patients = (outputevents[outputevents.admissionid.isin(AF_admission_dataset.admissionid)]).merge(AF_admission_dataset[[\"admissionid\",\"AF_measuredat\",\"date_corresponds_to_AF_admid\",\"intime\"]],how='left',on='admissionid')\n",
    "else:\n",
    "    output_fluid_pd_patients = (outputevents[outputevents.admissionid.isin(AF_admission_dataset.admissionid)]).merge(AF_admission_dataset[[\"admissionid\",\"AF_measuredat\",\"intime\"]],how='left',on='admissionid')\n",
    "\n",
    "#MIMIC specific preprocessing\n",
    "output_fluid_pd_patients.loc[:,\"measuredat\"]=(pd.to_datetime(output_fluid_pd_patients.measuredat)-output_fluid_pd_patients.intime).dt.total_seconds() #INTIME is already in datetime\n",
    "output_fluid_pd_patients = output_fluid_pd_patients.drop(columns=[\"intime\"])\n",
    "\n",
    "output_fluid_pd_patients[\"time_to_AF\"]=(output_fluid_pd_patients.AF_measuredat.values-60*60*margin_time) - output_fluid_pd_patients.measuredat.values #add one margin_time to AF extra\n",
    "output_fluid_pd_patients = output_fluid_pd_patients[(output_fluid_pd_patients.time_to_AF > (time_shift-margin_time)*60*60) & (output_fluid_pd_patients.time_to_AF/60/60 <= (time_shift+hours_to_first_AF-margin_time-1) )]\n",
    "\n",
    "output_af_features = None #RAM Optimization\n",
    "\n",
    "output_fluid_pd_patients_agg = output_fluid_pd_patients[[\"admissionid\",\"fluidout\"]].groupby([\"admissionid\"]).sum().reset_index()\n",
    "\n",
    "output_fluid_pd_patients_total = output_fluid_pd_patients_agg\n",
    "output_fluid_pd_patients = None #Save RAM\n",
    "output_fluid_pd_patients_agg = None\n",
    "\n",
    "fluid_total = output_fluid_pd_patients_total.merge(input_fluid_pd_patients_total,on=\"admissionid\",how=\"outer\")\n",
    "fluid_total[\"fluid_balance\"]=fluid_total.fluidin-fluid_total.fluidout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_dataset = AF_admission_dataset.merge(numeric_pd_patients_total,how='left',on='admissionid')\n",
    "AF_dataset = AF_dataset.merge(lab_items_patients_total,how='left',on='admissionid')\n",
    "AF_dataset = AF_dataset.merge(medication_patients_total,how='left',on='admissionid')\n",
    "AF_dataset = AF_dataset.merge(output_pd_patients_total,how='left',on='admissionid')\n",
    "AF_dataset = AF_dataset.merge(fluid_total,how='left',on='admissionid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_dataset[\"Weight\"] = AF_dataset[\"mean_Admission Weight (Kg)\"].values\n",
    "AF_dataset[\"Weight\"] = AF_dataset[\"Weight\"].fillna(AF_dataset[\"mean_Daily Weight\"])\n",
    "\n",
    "AF_dataset[\"Height\"] = AF_dataset[\"mean_Height\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if non_biased_model:\n",
    "    if not six_hour_model:\n",
    "        if one_half_hour_model:\n",
    "            AF_dataset.to_csv(mimic_extracted_path+\"AF_dataset_1_5_hours_no_af_distribution_matched.csv\",index=False)\n",
    "        else:\n",
    "            AF_dataset.to_csv(mimic_extracted_path+\"AF_dataset_12_hours_no_af_distribution_matched.csv\",index=False)\n",
    "    else:\n",
    "        AF_dataset.to_csv(mimic_extracted_path+\"AF_dataset_\"+str(time_shift)+\"_hours_no_af_distribution_matched.csv\",index=False)\n",
    "else:\n",
    "    if not six_hour_model:\n",
    "        if one_half_hour_model:\n",
    "            AF_dataset.to_csv(mimic_extracted_path+\"AF_dataset_1_5_hours.csv\",index=False)\n",
    "        else:\n",
    "            AF_dataset.to_csv(mimic_extracted_path+\"AF_dataset_12_hours.csv\",index=False)\n",
    "    else:\n",
    "        AF_dataset.to_csv(mimic_extracted_path+\"AF_dataset_\"+str(time_shift)+\"_hours.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1f392defe650829700f492eb57f9ca780dd56d6bebdcdeef32d1ec2c20a25b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
